@article{chernoff1952measure,
  title={A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations},
  author={Chernoff, Herman},
  journal={The Annals of Mathematical Statistics},
  pages={493--507},
  year={1952},
  publisher={JSTOR}
}

@incollection{hoeffding1994probability,
  title={Probability inequalities for sums of bounded random variables},
  author={Hoeffding, Wassily},
  booktitle={The collected works of Wassily Hoeffding},
  pages={409--426},
  year={1994},
  publisher={Springer}
}

@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{tropp2012user,
  title={User-friendly tail bounds for sums of random matrices},
  author={Tropp, Joel A},
  journal={Foundations of computational mathematics},
  volume={12},
  number={4},
  pages={389--434},
  year={2012},
  publisher={Springer}
}

@article{tropp2015introduction,
  title={An Introduction to Matrix Concentration Inequalities},
  author={Tropp, Joel A},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={8},
  number={1-2},
  pages={1--230},
  year={2015},
  publisher={Now Publishers Inc. Hanover, MA, USA}
}

@article{bubeck2015convex,
  title={Convex Optimization: Algorithms and Complexity},
  author={Bubeck, S{\'e}bastien},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={8},
  number={3-4},
  pages={231--357},
  year={2015},
  publisher={Now Publishers Inc. Hanover, MA, USA}
}

@article{woodruff2014sketching,
  title={Sketching as a Tool for Numerical Linear Algebra},
  author={Woodruff, David P and others},
  journal={Foundations and Trends{\textregistered} in Theoretical Computer Science},
  volume={10},
  number={1--2},
  pages={1--157},
  year={2014},
  publisher={Now Publishers, Inc.}
}

@article{jain2017non,
  title={Non-convex Optimization for Machine Learning},
  author={Jain, Prateek and Kar, Purushottam},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={10},
  number={3-4},
  pages={142--336},
  year={2017},
  publisher={Now Publishers Inc. Hanover, MA, USA}
}

@book{blum2020foundations,
  title={Foundations of data science},
  author={Blum, Avrim and Hopcroft, John and Kannan, Ravindran},
  year={2020},
  publisher={Cambridge University Press}
}

@book{tao2012topics,
  title={Topics in random matrix theory},
  author={Tao, Terence},
  volume={132},
  year={2012},
  publisher={American Mathematical Soc.}
}

@book{conway2019course,
  title={A course in functional analysis},
  author={Conway, John B},
  volume={96},
  year={2019},
  publisher={Springer}
}

@article{hazan2016introduction,
  title={Introduction to online convex optimization},
  author={Hazan, Elad and others},
  journal={Foundations and Trends{\textregistered} in Optimization},
  volume={2},
  number={3-4},
  pages={157--325},
  year={2016},
  publisher={Now Publishers, Inc.}
}

@inproceedings{clarkson2013low,
  title={Low rank approximation and regression in input sparsity time},
  author={Clarkson, Kenneth L and Woodruff, David P},
  booktitle={Proceedings of the forty-fifth annual ACM symposium on Theory of Computing},
  pages={81--90},
  year={2013}
}

@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Proceedings of the 32nd International Conference on Neural Information Processing Systems},
  pages={8580--8589},
  year={2018}
}

@article{allen2018convex,
  title={From Convex to Nonconvex Optimization: Algorithm Design and Global Convergence},
  author={Allen-Zhu, Zeyuan},
  year={2018}
}

@article{allen2018make,
  title={How To Make the Gradients Small Stochastically: Even Faster Convex and Nonconvex {SGD}},
  author={Allen-Zhu, Zeyuan},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={1157--1167},
  year={2018}
}

@inproceedings{bernstein2018signsgd,
  title={{signSGD}: Compressed optimisation for non-convex problems},
  author={Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Animashree},
  booktitle={International Conference on Machine Learning},
  pages={560--569},
  year={2018},
  organization={PMLR}
}

@inproceedings{chen2019convergence,
  title={On the Convergence of A Class of {Adam}-Type Algorithms for Non-Convex Optimization},
  author={Chen, Xiangyi and Liu, Sijia and Sun, Ruoyu and Hong, Mingyi},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{de2018convergence,
  title={Convergence guarantees for {RMSProp} and {Adam} in non-convex optimization and an empirical comparison to Nesterov acceleration},
  author={De, Soham and Mukherjee, Anirbit and Ullah, Enayat},
  journal={arXiv preprint arXiv:1807.06766},
  year={2018}
}

@article{defossez2020simple,
  title={A Simple Convergence Proof of {Adam} and {Adagrad}},
  author={D{\'e}fossez, Alexandre and Bottou, L{\'e}on and Bach, Francis and Usunier, Nicolas},
  journal={arXiv preprint arXiv:2003.02395},
  year={2020}
}

@article{dou2021one,
  title={On the One-sided Convergence of {Adam}-type Algorithms in Non-convex Non-concave Min-max Optimization},
  author={Dou, Zehao and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2109.14213},
  year={2021}
}

@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={7},
  year={2011}
}

@article{fang2019convergence,
  title={Convergence analyses of online {Adam} algorithm in convex setting and two-layer {ReLU} neural network},
  author={Fang, Biyi and Klabjan, Diego},
  journal={arXiv preprint arXiv:1905.09356},
  year={2019}
}

@article{ghadimi2013stochastic,
  title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2341--2368},
  year={2013},
  publisher={SIAM}
}

@article{ghadimi2016accelerated,
  title={Accelerated gradient methods for nonconvex nonlinear and stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={Mathematical Programming},
  volume={156},
  number={1-2},
  pages={59--99},
  year={2016},
  publisher={Springer}
}

@inproceedings{huang2019nostalgic,
  title={Nostalgic {Adam}: Weighting more of the past gradients when designing the adaptive learning rate},
  author={Huang, Haiwen and Wang, Chang and Dong, Bin},
  booktitle={28th International Joint Conference on Artificial Intelligence, IJCAI 2019},
  pages={2556--2562},
  year={2019}
}

@inproceedings{kingma2015adam,
  title={{Adam}: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@inproceedings{li2019convergence,
  title={On the convergence of stochastic gradient descent with adaptive stepsizes},
  author={Li, Xiaoyu and Orabona, Francesco},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={983--992},
  year={2019},
  organization={PMLR}
}

@inproceedings{lu2018accelerating,
  title={Accelerating greedy coordinate descent methods},
  author={Lu, Haihao and Freund, Robert and Mirrokni, Vahab},
  booktitle={International Conference on Machine Learning},
  pages={3257--3266},
  year={2018},
  organization={PMLR}
}

@inproceedings{reddi2018convergence,
  title={On the Convergence of {Adam} and Beyond},
  author={Reddi, Sashank J and Kale, Satyen and Kumar, Sanjiv},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{reddi2018adaptive,
  title={Adaptive methods for nonconvex optimization},
  author={Reddi, S and Zaheer, Manzil and Sachan, Devendra and Kale, Satyen and Kumar, Sanjiv},
  booktitle={Proceeding of 32nd Conference on Neural Information Processing Systems (NIPS 2018)},
  year={2018}
}

@inproceedings{ward2019adagrad,
  title={{AdaGrad} stepsizes: Sharp convergence over nonconvex landscapes},
  author={Ward, Rachel and Wu, Xiaoxia and Bottou, Leon},
  booktitle={International Conference on Machine Learning},
  pages={6677--6686},
  year={2019},
  organization={PMLR}
}

@article{yang2016unified,
 author={Yang, Tianbao and Lin, Qihang and Li, Zhe},
 journal={arXiv preprint arXiv:1604.03257},
 title={Unified convergence analysis of stochastic momentum methods for convex and non-convex optimization},
 year={2016}
}

@article{zhang2020adaptive,
  title={Why are Adaptive Methods Good for Attention Models?},
  author={Zhang, Jingzhao and Karimireddy, Sai Praneeth and Veit, Andreas and Kim, Seungyeon and Reddi, Sashank and Kumar, Sanjiv and Sra, Suvrit},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{zhou2018convergence,
 author={Zhou, Dongruo and Chen, Jinghui and Cao, Yuan and Tang, Yiqi and Yang, Ziyan and Gu, Quanquan},
 journal={arXiv preprint arXiv:1808.05671},
 title={On the convergence of adaptive gradient methods for nonconvex optimization},
 year={2018}
}

@inproceedings{zou2019sufficient,
  title={A sufficient condition for convergences of {Adam} and {RMSprop}},
  author={Zou, Fangyu and Shen, Li and Jie, Zequn and Zhang, Weizhong and Liu, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11127--11135},
  year={2019}
}

@article{zou2018weighted,
  title={Weighted {Adagrad} with unified momentum},
  author={Zou, Fangyu and Shen, Li and Jie, Zequn and Sun, Ju and Liu, Wei},
  journal={arXiv preprint arXiv:1808.03408},
  year={2018}
}

@article{richtarik2014iteration,
  title={Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function},
  author={Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
  journal={Mathematical Programming},
  volume={144},
  number={1},
  pages={1--38},
  year={2014},
  publisher={Springer}
}

@article{song2021training,
  title={Training Multi-Layer Over-Parametrized Neural Network in Subquadratic Time},
  author={Song, Zhao and Zhang, Lichen and Zhang, Ruizhe},
  journal={arXiv preprint arXiv:2112.07628},
  year={2021}
}

@inproceedings{van2021training,
  title={Training (Overparametrized) Neural Networks in Near-Linear Time},
  author={van den Brand, Jan and Peng, Binghui and Song, Zhao and Weinstein, Omri},
  booktitle={12th Innovations in Theoretical Computer Science Conference (ITCS 2021)},
  volume={185},
  pages={63},
  year={2021},
  organization={Schloss Dagstuhl--Leibniz-Zentrum f{\"u}r Informatik}
}

@inproceedings{cohen2021gradient,
  title={Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability},
  author={Cohen, Jeremy and Kaur, Simran and Li, Yuanzhi and Kolter, J Zico and Talwalkar, Ameet},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@book{martens2016second,
  title={Second-order optimization for neural networks},
  author={Martens, James},
  year={2016},
  publisher={University of Toronto (Canada)}
}

@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={Siam Review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}

@inproceedings{jacot2020asymptotic,
  title={The asymptotic spectrum of the Hessian of {DNN} throughout training},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{chen2021visualgpt,
  title={VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning},
  author={Chen, Jun and Guo, Han and Yi, Kai and Li, Boyang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2102.10407},
  year={2021}
}

@article{tsimpoukelli2021multimodal,
  title={Multimodal few-shot learning with frozen language models},
  author={Tsimpoukelli, Maria and Menick, Jacob and Cabi, Serkan and Eslami, SM and Vinyals, Oriol and Hill, Felix},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{du2020few,
  title={Few-Shot Learning via Learning the Representation, Provably},
  author={Du, Simon Shaolei and Hu, Wei and Kakade, Sham M and Lee, Jason D and Lei, Qi},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{bouniot2020towards,
  title={Towards better understanding meta-learning methods through multi-task representation learning theory},
  author={Bouniot, Quentin and Redko, Ievgen and Audigier, Romaric and Loesch, Ang{\'e}lique and Zotkin, Yevhenii and Habrard, Amaury},
  journal={arXiv preprint arXiv:2010.01992},
  year={2020}
}

@inproceedings{tripuraneni2021provable,
  title={Provable meta-learning of linear representations},
  author={Tripuraneni, Nilesh and Jin, Chi and Jordan, Michael},
  booktitle={International Conference on Machine Learning},
  pages={10434--10443},
  year={2021},
  organization={PMLR}
}

@article{arora2017provable,
  title={Provable benefits of representation learning},
  author={Arora, Sanjeev and Risteski, Andrej},
  journal={arXiv preprint arXiv:1706.04601},
  year={2017}
}

@article{rosenfeld2022domain,
  title={Domain-adjusted regression or: {ERM} may already learn features sufficient for out-of-distribution generalization},
  author={Rosenfeld, Elan and Ravikumar, Pradeep and Risteski, Andrej},
  journal={arXiv preprint arXiv:2202.06856},
  year={2022}
}

@article{arora2012multiplicative,
  title={The multiplicative weights update method: A meta-algorithm and applications},
  author={Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
  journal={Theory of computing},
  volume={8},
  number={1},
  pages={121--164},
  year={2012},
  publisher={Theory of Computing Exchange}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{cai2019gram,
  title={Gram-gauss-newton method: Learning overparameterized neural networks for regression problems},
  author={Cai, Tianle and Gao, Ruiqi and Hou, Jikai and Chen, Siyu and Wang, Dong and He, Di and Zhang, Zhihua and Wang, Liwei},
  journal={arXiv preprint arXiv:1905.11675},
  year={2019}
}

@article{allen2016lazysvd,
  title={LazySVD: Even faster SVD decomposition yet without agonizing pain},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{allen2019convergence,
  title={A convergence theory for deep learning via over-parameterization},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle={International Conference on Machine Learning},
  pages={242--252},
  year={2019},
  organization={PMLR}
}

@article{kawaguchi2016deep,
  title={Deep learning without poor local minima},
  author={Kawaguchi, Kenji},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{du2019gradient,
  title={Gradient Descent Provably Optimizes Over-parameterized Neural Networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{du2019gradient2,
  title={Gradient descent finds global minima of deep neural networks},
  author={Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
  booktitle={International conference on machine learning},
  pages={1675--1685},
  year={2019},
  organization={PMLR}
}

@inproceedings{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019},
  organization={PMLR}
}

@article{arora2019exact,
  title={On exact computation with an infinitely wide neural net},
  author={Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{allen2019learning,
  title={Learning and generalization in overparameterized neural networks, going beyond two layers},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{gutmann2010noise,
  title={Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author={Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={297--304},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{rhodes2020telescoping,
  title={Telescoping density-ratio estimation},
  author={Rhodes, Benjamin and Xu, Kai and Gutmann, Michael U},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4905--4916},
  year={2020}
}

@article{liu2021analyzing,
  title={Analyzing and Improving the Optimization Landscape of Noise-Contrastive Estimation},
  author={Liu, Bingbin and Rosenfeld, Elan and Ravikumar, Pradeep and Risteski, Andrej},
  journal={arXiv preprint arXiv:2110.11271},
  year={2021}
}

@inproceedings{devlin2019bert,
  title={{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4171--4186},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{tripuraneni2020theory,
  title={On the theory of transfer learning: The importance of task diversity},
  author={Tripuraneni, Nilesh and Jordan, Michael and Jin, Chi},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7852--7862},
  year={2020}
}

@inproceedings{kumar2022fine,
  title={Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution},
  author={Kumar, Ananya and Raghunathan, Aditi and Jones, Robbie Matthew and Ma, Tengyu and Liang, Percy},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@article{santurkar2018does,
  title={How does batch normalization help optimization?},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{wu2020understanding,
  title={Understanding and Improving Information Transfer in Multi-Task Learning},
  author={Wu, Sen and Zhang, Hongyang R and R{\'e}, Christopher},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{chua2021fine,
  title={How fine-tuning allows for effective meta-learning},
  author={Chua, Kurtland and Lei, Qi and Lee, Jason D},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8871--8884},
  year={2021}
}

@article{power2022grokking,
  title={Grokking: Generalization beyond overfitting on small algorithmic datasets},
  author={Power, Alethea and Burda, Yuri and Edwards, Harri and Babuschkin, Igor and Misra, Vedant},
  journal={arXiv preprint arXiv:2201.02177},
  year={2022}
}

@inproceedings{xie2021explanation,
  title={An Explanation of In-context Learning as Implicit Bayesian Inference},
  author={Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{thilak2022slingshot,
  title={The Slingshot Mechanism: An Empirical Study of Adaptive Optimizers and the Grokking Phenomenon},
  author={Thilak, Vimal and Littwin, Etai and Zhai, Shuangfei and Saremi, Omid and Paiss, Roni and Susskind, Joshua},
  journal={arXiv preprint arXiv:2206.04817},
  year={2022}
}

@article{liu2022towards,
  title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
  author={Liu, Ziming and Kitouni, Ouail and Nolte, Niklas and Michaud, Eric J and Tegmark, Max and Williams, Mike},
  journal={arXiv preprint arXiv:2205.10343},
  year={2022}
}

@inproceedings{kong2020meta,
  title={Meta-learning for mixed linear regression},
  author={Kong, Weihao and Somani, Raghav and Song, Zhao and Kakade, Sham and Oh, Sewoong},
  booktitle={International Conference on Machine Learning},
  pages={5394--5404},
  year={2020},
  organization={PMLR}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@article{maurer2016benefit,
  title={The benefit of multitask representation learning},
  author={Maurer, Andreas and Pontil, Massimiliano and Romera-Paredes, Bernardino},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={81},
  pages={1--32},
  year={2016}
}

@article{zou2021understanding,
  title={Understanding the generalization of {Adam} in learning neural networks with proper regularization},
  author={Zou, Difan and Cao, Yuan and Li, Yuanzhi and Gu, Quanquan},
  journal={arXiv preprint arXiv:2108.11371},
  year={2021}
}

@article{cooley1965algorithm,
  title={An algorithm for the machine calculation of complex Fourier series},
  author={Cooley, James W and Tukey, John W},
  journal={Mathematics of computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  publisher={JSTOR}
}

@inproceedings{ji2020polylogarithmic,
  title={Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow {ReLU} networks},
  author={Ji, Ziwei and Telgarsky, Matus},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{song2021fast,
  title={Fast sketching of polynomial kernels of polynomial degree},
  author={Song, Zhao and Woodruff, David and Yu, Zheng and Zhang, Lichen},
  booktitle={International Conference on Machine Learning},
  pages={9812--9823},
  year={2021},
  organization={PMLR}
}

@article{arora2022understanding,
  title={Understanding Gradient Descent on Edge of Stability in Deep Learning},
  author={Arora, Sanjeev and Li, Zhiyuan and Panigrahi, Abhishek},
  journal={arXiv preprint arXiv:2205.09745},
  year={2022}
}

@article{ahn2022understanding,
  title={Understanding the unstable convergence of gradient descent},
  author={Ahn, Kwangjun and Zhang, Jingzhao and Sra, Suvrit},
  journal={arXiv preprint arXiv:2204.01050},
  year={2022}
}

@article{balles2020geometry,
  title={The geometry of sign gradient descent},
  author={Balles, Lukas and Pedregosa, Fabian and Roux, Nicolas Le},
  journal={arXiv preprint arXiv:2002.08056},
  year={2020}
}

@inproceedings{balles2018dissecting,
  title={Dissecting {Adam}: The sign, magnitude and variance of stochastic gradients},
  author={Balles, Lukas and Hennig, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={404--413},
  year={2018},
  organization={PMLR}
}

@inproceedings{sun2016deep,
  title={Deep {CORAL}: Correlation alignment for deep domain adaptation},
  author={Sun, Baochen and Saenko, Kate},
  booktitle={European conference on computer vision},
  pages={443--450},
  year={2016},
  organization={Springer}
}

@inproceedings{xie2020adversarial,
  title={Adversarial examples improve image recognition},
  author={Xie, Cihang and Tan, Mingxing and Gong, Boqing and Wang, Jiang and Yuille, Alan L and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={819--828},
  year={2020}
}

@inproceedings{zhang2020gradient,
  title={Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity},
  author={Zhang, Jingzhao and He, Tianxing and Sra, Suvrit and Jadbabaie, Ali},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{wen2022mechanism,
  title={The Mechanism of Prediction Head in Non-contrastive Self-supervised Learning},
  author={Wen, Zixin and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2205.06226},
  year={2022}
}

@inproceedings{wen2021toward,
  title={Toward understanding the feature learning process of self-supervised contrastive learning},
  author={Wen, Zixin and Li, Yuanzhi},
  booktitle={International Conference on Machine Learning},
  pages={11112--11122},
  year={2021},
  organization={PMLR}
}

@inproceedings{ahle2020oblivious,
  title={Oblivious sketching of high-degree polynomial kernels},
  author={Ahle, Thomas D and Kapralov, Michael and Knudsen, Jakob BT and Pagh, Rasmus and Velingker, Ameya and Woodruff, David P and Zandieh, Amir},
  booktitle={Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={141--160},
  year={2020},
  organization={SIAM}
}

@inproceedings{munteanu2022bounding,
  title={Bounding the Width of Neural Networks via Coupled Initialization -- A Worst Case Analysis},
  author={Munteanu, Alexander and Omlor, Simon and Song, Zhao and Woodruff, David},
  booktitle={International Conference on Machine Learning},
  pages={16083--16122},
  year={2022},
  organization={PMLR}
}

@inproceedings{hron2020infinite,
  title={Infinite attention: {NNGP} and {NTK} for deep attention networks},
  author={Hron, Jiri and Bahri, Yasaman and Sohl-Dickstein, Jascha and Novak, Roman},
  booktitle={International Conference on Machine Learning},
  pages={4376--4386},
  year={2020},
  organization={PMLR}
}

@inproceedings{zhang2019gradient,
  title={Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity},
  author={Zhang, Jingzhao and He, Tianxing and Sra, Suvrit and Jadbabaie, Ali},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{nagarajan2019generalization,
  title={Generalization in deep networks: The role of distance from initialization},
  author={Nagarajan, Vaishnavh and Kolter, J Zico},
  journal={arXiv preprint arXiv:1901.01672},
  year={2019}
}

@article{cohen2022adaptive,
  title={Adaptive Gradient Methods at the Edge of Stability},
  author={Cohen, Jeremy M and Ghorbani, Behrooz and Krishnan, Shankar and Agarwal, Naman and Medapati, Sourabh and Badura, Michal and Suo, Daniel and Cardoze, David and Nado, Zachary and Dahl, George E and others},
  journal={arXiv preprint arXiv:2207.14484},
  year={2022}
}

@article{barakat2021convergence,
  title={Convergence and dynamical behavior of the ADAM algorithm for nonconvex stochastic optimization},
  author={Barakat, Anas and Bianchi, Pascal},
  journal={SIAM Journal on Optimization},
  volume={31},
  number={1},
  pages={244--274},
  year={2021},
  publisher={SIAM}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@inproceedings{shazeer2018adafactor,
  title={Adafactor: Adaptive learning rates with sublinear memory cost},
  author={Shazeer, Noam and Stern, Mitchell},
  booktitle={International Conference on Machine Learning},
  pages={4596--4604},
  year={2018},
  organization={PMLR}
}

@inproceedings{tiedemann2012parallel,
  title={Parallel Data, Tools and Interfaces in {OPUS}},
  author={Tiedemann, J{\"o}rg},
  booktitle={Eight International Conference on Language Resources and Evaluation, MAY 21-27, 2012, Istanbul, Turkey},
  pages={2214--2218},
  year={2012}
}

@inproceedings{maas2011learning,
  title={Learning word vectors for sentiment analysis},
  author={Maas, Andrew and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies},
  pages={142--150},
  year={2011}
}

@article{raffel2020exploring,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of Machine Learning Research},
  volume={21},
  pages={1--67},
  year={2020}
}

@article{sanh2019distilbert,
  title={{DistilBERT}, a distilled version of {BERT}: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{armijo1966minimization,
  title={Minimization of functions having {Lipschitz} continuous first partial derivatives},
  author={Armijo, Larry},
  journal={Pacific Journal of mathematics},
  volume={16},
  number={1},
  pages={1--3},
  year={1966},
  publisher={Mathematical Sciences Publishers}
}

@article{polyakintroduction,
  title={Introduction to optimization. 1987},
  author={Polyak, Boris T},
  journal={Optimization Software, Inc, New York}
}

@article{tieleman2012lecture,
  title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen and Hinton, Geoffrey and others},
  journal={COURSERA: Neural networks for machine learning},
  volume={4},
  number={2},
  pages={26--31},
  year={2012}
}

@article{phuong2019convergence,
  title={On the Convergence Proof of {AMSGrad} and a New Version},
  author={Phuong, Tran Thi and Phong, Le Trieu},
  journal={arXiv preprint arXiv:1904.03590},
  year={2019}
}

@article{bottou1991stochastic,
  title={Stochastic gradient learning in neural networks},
  author={Bottou, L{\'e}on and others},
  journal={Proceedings of Neuro-N{\i}mes},
  volume={91},
  number={8},
  pages={12},
  year={1991},
  publisher={Nimes}
}

@article{mcmahan2010adaptive,
  title={Adaptive bound optimization for online convex optimization},
  author={McMahan, H Brendan and Streeter, Matthew},
  journal={arXiv preprint arXiv:1002.4908},
  year={2010}
}

@article{zou2018convergence,
  title={On the convergence of weighted adagrad with momentum for training deep neural networks},
  author={Zou, Fangyu and Shen, Li},
  journal={arXiv preprint arXiv:1808.03408},
  year={2018}
}

@incollection{danilova2022recent,
  title={Recent theoretical advances in non-convex optimization},
  author={Danilova, Marina and Dvurechensky, Pavel and Gasnikov, Alexander and Gorbunov, Eduard and Guminov, Sergey and Kamzolov, Dmitry and Shibaev, Innokentiy},
  booktitle={High-Dimensional Optimization and Probability},
  pages={79--163},
  year={2022},
  publisher={Springer}
}

@article{duchi2013estimation,
  title={Estimation, optimization, and parallelism when data is sparse},
  author={Duchi, John and Jordan, Michael I and McMahan, Brendan},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@article{levy2016power,
  title={The power of normalization: Faster evasion of saddle points},
  author={Levy, Kfir Y},
  journal={arXiv preprint arXiv:1611.04831},
  year={2016}
}

@article{hazan2015beyond,
  title={Beyond convexity: Stochastic quasi-convex optimization},
  author={Hazan, Elad and Levy, Kfir and Shalev-Shwartz, Shai},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{pan2022toward,
  title={Toward Understanding Why {Adam} Converges Faster Than {SGD} for Transformers},
  author={Pan, Yan and Li, Yuanzhi},
  booktitle={OPT 2022: Optimization for Machine Learning (NeurIPS 2022 Workshop)},
  year={2022},
  url={https://openreview.net/forum?id=Sf1NlV2r6PO}
}

@inproceedings{foret2021sharpness,
  title={Sharpness-aware Minimization for Efficiently Improving Generalization},
  author={Foret, Pierre and Kleiner, Ariel and Mobahi, Hossein and Neyshabur, Behnam},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{shalev2012online,
  title={Online learning and online convex optimization},
  author={Shalev-Shwartz, Shai and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={4},
  number={2},
  pages={107--194},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={5},
  number={1},
  pages={1--122},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{slivkins2019introduction,
  title={Introduction to multi-armed bandits},
  author={Slivkins, Aleksandrs and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={12},
  number={1-2},
  pages={1--286},
  year={2019},
  publisher={Now Publishers, Inc.}
}

@inproceedings{flaxman2005online,
  title={Online convex optimization in the bandit setting: gradient descent without a gradient},
  author={Flaxman, Abraham D and Kalai, Adam Tauman and McMahan, H Brendan},
  booktitle={Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={385--394},
  year={2005}
}

@inproceedings{agarwal2010optimal,
  title={Optimal Algorithms for Online Convex Optimization with Multi-Point Bandit Feedback.},
  author={Agarwal, Alekh and Dekel, Ofer},
  booktitle={COLT},
  pages={28--40},
  year={2010},
  organization={Citeseer}
}

@inproceedings{saha2011improved,
  title={Improved regret guarantees for online smooth convex optimization with bandit feedback},
  author={Saha, Ankan and Tewari, Ambuj},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={636--642},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{shamir2017optimal,
  title={An Optimal Algorithm for Bandit and Zero-Order Convex Optimization with Two-Point Feedback},
  author={Shamir, Ohad},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={52},
  pages={1--11},
  year={2017}
}

@inproceedings{zinkevich2003online,
  title={Online convex programming and generalized infinitesimal gradient ascent},
  author={Zinkevich, Martin},
  booktitle={Proceedings of the 20th International Conference on Machine Learning},
  pages={928--936},
  year={2003}
}

@inproceedings{abernethy2009beating,
  title={Beating the adaptive bandit with high probability},
  author={Abernethy, Jacob and Rakhlin, Alexander},
  booktitle={2009 Information Theory and Applications Workshop},
  pages={280--289},
  year={2009},
  organization={IEEE}
}

@inproceedings{abernethy2008competing,
  title={Competing in the dark: An efficient algorithm for bandit linear optimization},
  author={Abernethy, Jacob and Hazan, Elad and Rakhlin, Alexander},
  booktitle={21st Annual Conference on Learning Theory, COLT 2008},
  year={2008}
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{bravo2018bandit,
  title={Bandit learning in concave N-person games},
  author={Bravo, Mario and Leslie, David and Mertikopoulos, Panayotis},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{chen2023symbolic,
  title={Symbolic discovery of optimization algorithms},
  author={Chen, Xiangning and Liang, Chen and Huang, Da and Real, Esteban and Wang, Kaiyuan and Liu, Yao and Pham, Hieu and Dong, Xuanyi and Luong, Thang and Hsieh, Cho-Jui and others},
  journal={arXiv preprint arXiv:2302.06675},
  year={2023}
}

@software{black2021gpt,
  author={Black, Sid and Gao, Leo and Wang, Phil and Leahy, Connor and Biderman, Stella},
  title={{GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow}},
  month={mar},
  year={2021},
  note={{If you use this software, please cite it using these metadata.}},
  publisher={Zenodo},
  version={1.0},
  doi={10.5281/zenodo.5297715},
  url={https://doi.org/10.5281/zenodo.5297715}
}

@article{gao2020pile,
  title={The Pile: An 800GB Dataset of Diverse Text for Language Modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}

@article{jiang2022does,
  title={How Does Adaptive Optimization Impact Local Neural Network Geometry?},
  author={Jiang, Kaiqi and Malik, Dhruv and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2211.02254},
  year={2022}
}

@article{gorbunov2022clipped,
  title={Clipped stochastic methods for variational inequalities with heavy-tailed noise},
  author={Gorbunov, Eduard and Danilova, Marina and Dobre, David and Dvurechenskii, Pavel and Gasnikov, Alexander and Gidel, Gauthier},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={31319--31332},
  year={2022}
}

@article{wright2015coordinate,
  title={Coordinate descent algorithms},
  author={Wright, Stephen J},
  journal={Mathematical programming},
  volume={151},
  number={1},
  pages={3--34},
  year={2015},
  publisher={Springer}
}

@article{shi2016primer,
  title={A primer on coordinate descent algorithms},
  author={Shi, Hao-Jun Michael and Tu, Shenyinying and Xu, Yangyang and Yin, Wotao},
  journal={arXiv preprint arXiv:1610.00040},
  year={2016}
}

@inproceedings{mangold2023high,
  title={High-Dimensional Private Empirical Risk Minimization by Greedy Coordinate Descent},
  author={Mangold, Paul and Bellet, Aur{\'e}lien and Salmon, Joseph and Tommasi, Marc},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4894--4916},
  year={2023},
  organization={PMLR}
}

@article{pasande2022stochastic,
  title={Stochastic First-Order Learning for Large-Scale Flexibly Tied Gaussian Mixture Model},
  author={Pasande, Mohammad and Hosseini, Reshad and Araabi, Babak Nadjar},
  journal={arXiv preprint arXiv:2212.05402},
  year={2022}
}

@inproceedings{mangold2022differentially,
  title={Differentially private coordinate descent for composite empirical risk minimization},
  author={Mangold, Paul and Bellet, Aur{\'e}lien and Salmon, Joseph and Tommasi, Marc},
  booktitle={International Conference on Machine Learning},
  pages={14948--14978},
  year={2022},
  organization={PMLR}
}

@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={1310--1318},
  year={2013},
  organization={PMLR}
}

@article{pichapati2019adaclip,
  title={AdaCliP: Adaptive clipping for private SGD},
  author={Pichapati, Venkatadheeraj and Suresh, Ananda Theertha and Yu, Felix X and Reddi, Sashank J and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:1908.07643},
  year={2019}
}

@article{kocetkov2022stack,
  title={The Stack: 3 TB of permissively licensed source code},
  author={Kocetkov, Denis and Li, Raymond and Allal, Loubna Ben and Li, Jia and Mou, Chenghao and Ferrandis, Carlos Mu{\~n}oz and Jernite, Yacine and Mitchell, Margaret and Hughes, Sean and Wolf, Thomas and others},
  journal={arXiv preprint arXiv:2211.15533},
  year={2022}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{krizhevsky2009learning,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={Krizhevsky, Alex},
  year={2009}
}

@article{dimitrov2023plane,
  title={PlanE: Representation Learning over Planar Graphs},
  author={Dimitrov, Radoslav and Zhao, Zeyang and Abboud, Ralph and Ceylan, {\.I}smail {\.I}lkan},
  journal={arXiv preprint arXiv:2307.01180},
  year={2023}
}

@inproceedings{walters2021trajectory,
  title={Trajectory Prediction using Equivariant Continuous Convolution},
  author={Walters, Robin and Li, Jinxi Leo and Yu, Rose},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{gabillon2011multi,
  title={Multi-bandit best arm identification},
  author={Gabillon, Victor and Ghavamzadeh, Mohammad and Lazaric, Alessandro and Bubeck, S{\'e}bastien},
  journal={Advances in Neural Information Processing Systems},
  volume={24},
  year={2011}
}

@inproceedings{wang2023efficient,
  author={Wang, Xue and Wei, Mike Mingcheng and Yao, Tao},
  title={Efficient Sparse Linear Bandits under High Dimensional Data},
  year={2023},
  url={https://doi.org/10.1145/3580305.3599329},
  doi={10.1145/3580305.3599329},
  booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={2431â€“2443},
  numpages={13},
}

@inproceedings{audibert2010best,
  title={Best arm identification in multi-armed bandits.},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien and Munos, R{\'e}mi},
  booktitle={COLT},
  pages={41--53},
  year={2010}
}

@inproceedings{abbasi2012online,
  title={Online-to-confidence-set conversions and application to sparse stochastic bandits},
  author={Abbasi-Yadkori, Yasin and Pal, David and Szepesvari, Csaba},
  booktitle={Artificial Intelligence and Statistics},
  pages={1--9},
  year={2012},
  organization={PMLR}
}

@inproceedings{oh2021sparsity,
  title={Sparsity-agnostic lasso bandit},
  author={Oh, Min-hwan and Iyengar, Garud and Zeevi, Assaf},
  booktitle={International Conference on Machine Learning},
  pages={8271--8280},
  year={2021},
  organization={PMLR}
}

@article{kim2019doubly,
  title={Doubly-robust lasso bandit},
  author={Kim, Gi-Soo and Paik, Myunghee Cho},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{yang2016sparse,
  title={Sparse nonlinear regression: Parameter estimation under nonconvexity},
  author={Yang, Zhuoran and Wang, Zhaoran and Liu, Han and Eldar, Yonina and Zhang, Tong},
  booktitle={International Conference on Machine Learning},
  pages={2472--2481},
  year={2016},
  organization={PMLR}
}

@inproceedings{lu2019multi,
  title={Multi-objective generalized linear bandits},
  author={Lu, Shiyin and Wang, Guanghui and Hu, Yao and Zhang, Lijun},
  booktitle={Proceedings of the 28th International Joint Conference on Artificial Intelligence},
  pages={3080--3086},
  year={2019}
}

@inproceedings{chu2011contextual,
  title={Contextual bandits with linear payoff functions},
  author={Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={208--214},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{dong2022decomposable,
  title={Decomposable Non-Smooth Convex Optimization with Nearly-Linear Gradient Oracle Complexity},
  author={Dong, Sally and Jiang, Haotian and Lee, Yin Tat and Padmanabhan, Swati and Ye, Guanghao},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30756--30769},
  year={2022}
}

@article{schmidt2017minimizing,
  title={Minimizing finite sums with the stochastic average gradient},
  author={Schmidt, Mark and Le Roux, Nicolas and Bach, Francis},
  journal={Mathematical Programming},
  volume={162},
  pages={83--112},
  year={2017},
  publisher={Springer}
}

@inproceedings{joachims2006training,
  title={Training linear SVMs in linear time},
  author={Joachims, Thorsten},
  booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={217--226},
  year={2006}
}

@article{recht2011hogwild,
  title={Hogwild!: A lock-free approach to parallelizing stochastic gradient descent},
  author={Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={661--670},
  year={2010}
}

@article{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@article{brooks2024video,
  title={Video generation models as world simulators},
  author={Tim Brooks and Bill Peebles and Connor Holmes and Will DePue and Yufei Guo and Li Jing and David Schnurr and Joe Taylor and Troy Luhman and Eric Luhman and Clarence Ng and Ricky Wang and Aditya Ramesh},
  year={2024},
  url={https://openai.com/research/video-generation-models-as-world-simulators},
}

@article{lu2018learning,
  title={Learning under concept drift: A review},
  author={Lu, Jie and Liu, Anjin and Dong, Fan and Gu, Feng and Gama, Joao and Zhang, Guangquan},
  journal={IEEE transactions on knowledge and data engineering},
  volume={31},
  number={12},
  pages={2346--2363},
  year={2018},
  publisher={IEEE}
}

@article{vzliobaite2016overview,
  title={An overview of concept drift applications},
  author={{\v{Z}}liobait{\.e}, Indr{\.e} and Pechenizkiy, Mykola and Gama, Joao},
  journal={Big data analysis: new algorithms for a new society},
  pages={91--114},
  year={2016},
  publisher={Springer}
}

@article{gama2014survey,
  title={A survey on concept drift adaptation},
  author={Gama, Jo{\~a}o and {\v{Z}}liobait{\.e}, Indr{\.e} and Bifet, Albert and Pechenizkiy, Mykola and Bouchachia, Abdelhamid},
  journal={ACM computing surveys (CSUR)},
  volume={46},
  number={4},
  pages={1--37},
  year={2014},
  publisher={ACM New York, NY, USA}
}

@inproceedings{bach2008paired,
  title={Paired learners for concept drift},
  author={Bach, Stephen H and Maloof, Marcus A},
  booktitle={2008 Eighth IEEE International Conference on Data Mining},
  pages={23--32},
  year={2008},
  organization={IEEE}
}

@inproceedings{li2022ddg,
  title={{DDG-DA}: Data distribution generation for predictable concept drift adaptation},
  author={Li, Wendi and Yang, Xiao and Liu, Weiqing and Xia, Yingce and Bian, Jiang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={4},
  pages={4092--4100},
  year={2022}
}

@inproceedings{riva2022addressing,
  title={Addressing non-stationarity in {FX} trading with online model selection of offline {RL} experts},
  author={Riva, Antonio and Bisi, Lorenzo and Liotet, Pierre and Sabbioni, Luca and Vittori, Edoardo and Pinciroli, Marco and Trapletti, Michele and Restelli, Marcello},
  booktitle={Proceedings of the Third ACM International Conference on AI in Finance},
  pages={394--402},
  year={2022}
}

@inproceedings{ye2022future,
  title={Future gradient descent for adapting the temporal shifting data distribution in online recommendation systems},
  author={Ye, Mao and Jiang, Ruichen and Wang, Haoxiang and Choudhary, Dhruv and Du, Xiaocong and Bhushanam, Bhargav and Mokhtari, Aryan and Kejariwal, Arun and Liu, Qiang},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={2256--2266},
  year={2022},
  organization={PMLR}
}

@inproceedings{bifet2007learning,
  title={Learning from time-changing data with adaptive windowing},
  author={Bifet, Albert and Gavalda, Ricard},
  booktitle={Proceedings of the 2007 SIAM International Conference on Data Mining},
  pages={443--448},
  year={2007},
  organization={SIAM}
}

@article{gomes2017adaptive,
  title={Adaptive random forests for evolving data stream classification},
  author={Gomes, Heitor M and Bifet, Albert and Read, Jesse and Barddal, Jean Paul and Enembreck, Fabr{\'\i}cio and Pfharinger, Bernhard and Holmes, Geoff and Abdessalem, Talel},
  journal={Machine Learning},
  volume={106},
  pages={1469--1495},
  year={2017},
  publisher={Springer}
}

@article{kolter2007dynamic,
  title={Dynamic weighted majority: An ensemble method for drifting concepts},
  author={Kolter, J Zico and Maloof, Marcus A},
  journal={The Journal of Machine Learning Research},
  volume={8},
  pages={2755--2790},
  year={2007},
  publisher={JMLR. org}
}

@article{elwell2011incremental,
  title={Incremental learning of concept drift in nonstationary environments},
  author={Elwell, Ryan and Polikar, Robi},
  journal={IEEE transactions on neural networks},
  volume={22},
  number={10},
  pages={1517--1531},
  year={2011},
  publisher={IEEE}
}

@article{brzezinski2013reacting,
  title={Reacting to different types of concept drift: The accuracy updated ensemble algorithm},
  author={Brzezinski, Dariusz and Stefanowski, Jerzy},
  journal={IEEE transactions on neural networks and learning systems},
  volume={25},
  number={1},
  pages={81--94},
  year={2013},
  publisher={IEEE}
}

@inproceedings{zhang2008categorizing,
  title={Categorizing and mining concept drifting data streams},
  author={Zhang, Peng and Zhu, Xingquan and Shi, Yong},
  booktitle={Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={812--820},
  year={2008}
}

@inproceedings{domingos2000mining,
  title={Mining high-speed data streams},
  author={Domingos, Pedro and Hulten, Geoff},
  booktitle={Proceedings of the sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={71--80},
  year={2000}
}

@inproceedings{hulten2001mining,
  title={Mining time-changing data streams},
  author={Hulten, Geoff and Spencer, Laurie and Domingos, Pedro},
  booktitle={Proceedings of the seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={97--106},
  year={2001}
}

@inproceedings{gama2003accurate,
  title={Accurate decision trees for mining high-speed data streams},
  author={Gama, Joao and Rocha, Ricardo and Medas, Pedro},
  booktitle={Proceedings of the ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={523--528},
  year={2003}
}

@article{frias2016online,
  title={Online adaptive decision trees based on concentration inequalities},
  author={Frias-Blanco, Isvani and del Campo-Avila, Jose and Ramos-Jimenez, Gonzalo and Carvalho, Andre CPLF and Ortiz-D{\'\i}az, Agust{\'\i}n and Morales-Bueno, Rafael},
  journal={Knowledge-Based Systems},
  volume={104},
  pages={179--194},
  year={2016},
  publisher={Elsevier}
}

@article{rutkowski2013decision,
  title={Decision trees for mining data streams based on the gaussian approximation},
  author={Rutkowski, Leszek and Jaworski, Maciej and Pietruczuk, Lena and Duda, Piotr},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={26},
  number={1},
  pages={108--119},
  year={2013},
  publisher={IEEE}
}

@article{rutkowski2012decision,
  title={Decision trees for mining data streams based on the McDiarmid's bound},
  author={Rutkowski, Leszek and Pietruczuk, Lena and Duda, Piotr and Jaworski, Maciej},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={25},
  number={6},
  pages={1272--1279},
  year={2012},
  publisher={IEEE}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  year={2005},
  publisher={Microtome Publishing, Brookline, United States-Massachusetts}
}

@article{wei2016tracking,
  title={Tracking the best expert in non-stationary stochastic environments},
  author={Wei, Chen-Yu and Hong, Yi-Te and Lu, Chi-Jen},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@book{bosq2000linear,
  title={Linear processes in function spaces: Theory and applications},
  author={Bosq, Denis},
  volume={149},
  year={2000},
  publisher={Springer Science \& Business Media}
}

@article{wang2020practical,
  title={A practical incremental method to train deep {CTR} models},
  author={Wang, Yichao and Guo, Huifeng and Tang, Ruiming and Liu, Zhirong and He, Xiuqiang},
  journal={arXiv preprint arXiv:2009.02147},
  year={2020}
}

@inproceedings{soare2014multi,
  title={Multi-task linear bandits},
  author={Soare, Marta and Alsharif, Ouais and Lazaric, Alessandro and Pineau, Joelle},
  booktitle={NIPS2014 workshop on transfer and multi-task learning: theory meets practice},
  year={2014}
}

@inproceedings{dimakopoulou2019balanced,
  title={Balanced linear contextual bandits},
  author={Dimakopoulou, Maria and Zhou, Zhengyuan and Athey, Susan and Imbens, Guido},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={3445--3453},
  year={2019}
}

@article{kannan2018smoothed,
  title={A smoothed analysis of the greedy algorithm for the linear contextual bandit problem},
  author={Kannan, Sampath and Morgenstern, Jamie H and Roth, Aaron and Waggoner, Bo and Wu, Zhiwei Steven},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{auer2002using,
  title={Using confidence bounds for exploitation-exploration trade-offs},
  author={Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Nov},
  pages={397--422},
  year={2002}
}

@article{dimakopoulou2017estimation,
  title={Estimation considerations in contextual bandits},
  author={Dimakopoulou, Maria and Zhou, Zhengyuan and Athey, Susan and Imbens, Guido},
  journal={arXiv preprint arXiv:1711.07077},
  year={2017}
}

